#!/usr/bin/env python3
import logging
import argparse
import os
import re
import sys
import json
import zipfile
import subprocess
import shutil
from itertools import groupby
from html.parser import HTMLParser
from urllib import request

DEFAULT_MAVEN = os.path.join(os.environ["HOME"], ".m2")
DEFAULT_GRADLE = os.path.join(os.environ["HOME"], ".gradle")
DEFAULT_OUTPUT = os.path.join(os.environ["HOME"], "jdoc")
DIRNAME_JAVADOC = "javadoc"
DIRNAME_SOURCES = "sources"
FILENAME_INDEX = "_index.json"
FILENAME_CLASS = [
    "allclasses-noframe.html",
    "allclasses-index.html",
    "overview-tree.html",
]
JDK = "JDK"


def get_output_dirname(filename):
    if filename.endswith("-javadoc.jar"):
        return DIRNAME_JAVADOC
    elif filename.endswith("-sources.jar"):
        return DIRNAME_SOURCES
    else:
        raise ValueError(filename)


def index_javadoc(repodir, outputdir):
    """
    Extracts Javadoc archives.
    """
    if not os.path.exists(repodir):
        logging.warning("Repo does not exist: %s", repodir)
        return
    logging.info("Indexing repo: %s", repodir)
    os.makedirs(os.path.join(outputdir, DIRNAME_JAVADOC), exist_ok=True)
    os.makedirs(os.path.join(outputdir, DIRNAME_SOURCES), exist_ok=True)
    for root, dirnames, filenames in os.walk(repodir):
        for filename in filenames:
            if filename.endswith("-javadoc.jar") or filename.endswith("-sources.jar"):
                pathname_input = os.path.join(root, filename)
                pathname_output = os.path.join(
                    outputdir, get_output_dirname(filename), filename
                )
                if not os.path.exists(pathname_output):
                    logging.debug(
                        "Extracting %s to %s", pathname_input, pathname_output
                    )
                    os.makedirs(pathname_output, exist_ok=True)
                    with zipfile.ZipFile(pathname_input) as zf:
                        zf.extractall(pathname_output)


class LinkExtractor(HTMLParser):
    """
    Extracts links to local Javadoc from an HTML document.
    """

    def __init__(self, include_external=False):
        super().__init__()
        self.include_external = include_external
        self.links = []

    def _is_code(self, title):
        return title and ("class in" in title or "interface in" in title)

    def _is_local(self, href):
        return (
            href
            and "http://" not in href
            and "https://" not in href
            and "is-external=true" not in href
        )

    def handle_starttag(self, tag, attrs):
        if tag == "a":
            attrs = dict(attrs)
            title = attrs.get("title")
            href = attrs.get("href")
            if self._is_code(title) and (self.include_external or self._is_local(href)):
                self.links.append(href)

    def get_links(self):
        """
        :return: List of the extracted links to classes and interfaces.
        """
        return self.links


def parse_classnames(root, html_content):
    """
    Extracts all classes and interfaces from Javadoc index.
    """
    parser = LinkExtractor()
    parser.feed(html_content)
    return [
        dict(
            name=link.replace(".html", "").replace("/", "."),
            path=link,
            jar=os.path.basename(root),
        )
        for link in parser.get_links()
    ]


def list_build_files():
    """
    Finds all Maven/Gradle build files in user's home directory.

    :yield: The absolute path to the build file.
    """
    for root, dirnames, filenames in os.walk(os.environ["HOME"]):
        dirnames[:] = [
            d for d in dirnames if d not in ["jdoc", "tmp"] and not d.startswith(".")
        ]
        for filename in filenames:
            if filename == "pom.xml" or filename == "build.gradle":
                pathname = os.path.join(root, filename)
                yield pathname


def get_last_modified_time(pathname):
    """
    :return: The last modified time of ``pathname``.
    """
    return int(os.path.getmtime(pathname))


def get_java_version():
    """
    Runs ``java -version`` and extracts the major version.

    :return: The major version of Java found on the user's path.
    """
    output = subprocess.check_output(
        ["java", "-version"], stderr=subprocess.STDOUT
    ).decode("utf-8")
    match = re.search(r'version "(\d+)\.', output)
    if not match:
        raise Exception("Could not find Java version in output of java -version")
    java_version = int(match.group(1))
    logging.info("Identified system Java version as %s", java_version)
    return java_version


def parse_standard_library_classnames(java_version):
    """
    Finds links to Javadoc for the JDK from the web.
    """
    base_url = (
        "https://docs.oracle.com/en/java/javase/" + str(java_version) + "/docs/api/"
    )
    all_classes_url = base_url + "allclasses-index.html"
    with request.urlopen(all_classes_url) as response:
        logging.info("GET %s => %s", all_classes_url, response.getcode())
        html_content = response.read().decode("utf-8")
        parser = LinkExtractor(include_external=True)
        parser.feed(html_content)
        return [
            dict(
                name=link.replace(".html", "").replace("/", "."),
                path=base_url + link,
                jar=JDK,
            )
            for link in parser.get_links()
        ]


def index_json(outputdir):
    """
    Builds the JSON index file containing all classes.

    The index file consists of a list of all the classes and the location
    of their Javadocs, and a mapping of all local build files to their last
    changed timestamp, so we can know if dependencies have changed.
    """
    logging.info("Building %s", FILENAME_INDEX)
    # Find classnames from standard library and libraries
    classnames = []
    classnames.extend(parse_standard_library_classnames(get_java_version()))
    for root, dirnames, filenames in os.walk(os.path.join(outputdir, DIRNAME_JAVADOC)):
        for filename in filenames:
            if filename in FILENAME_CLASS:
                pathname = os.path.join(root, filename)
                logging.debug("Processing %s", pathname)
                with open(pathname, encoding="unicode_escape") as f:
                    html_content = f.read()
                    classnames.extend(parse_classnames(root, html_content))
    # Find build files and record their last modified times
    pomfiles = {}
    for pathname in list_build_files():
        last_modified = get_last_modified_time(pathname)
        logging.info("Build file %s last modified at %s", pathname, last_modified)
        pomfiles[pathname] = dict(last_modified=last_modified)
    # Write JSON file
    with open(os.path.join(outputdir, FILENAME_INDEX), "w") as f:
        json.dump(dict(classnames=classnames, pomfiles=pomfiles), f)


def index(mavendir, gradledir, outputdir, delete=False):
    """
    Runs indexing pipeline.
    """
    if delete and os.path.exists(outputdir):
        logging.info("Deleting %s", outputdir)
        shutil.rmtree(outputdir)
    index_javadoc(mavendir, outputdir)
    index_javadoc(gradledir, outputdir)
    index_json(outputdir)


def load_index(dirname):
    """
    :return: The index JSON file.
    """
    with open(os.path.join(dirname, FILENAME_INDEX)) as f:
        return json.load(f)


def classname_matches(classname, patterns, flags=0, exact_name=False):
    """
    Returns True if a class matches search patterns.
    """
    if patterns:
        for pattern in patterns:
            if (exact_name and classname["name"].split(".")[-1] == pattern) or (
                not exact_name
                and (
                    re.search(pattern, classname["name"], flags)
                    or re.search(pattern, classname["jar"], flags)
                )
            ):
                return True
    return False


PATTERN_VERSION = re.compile(r"(\d+)\.(\d+)\.(\d+)")


def parse_version_parts(version):
    try:
        match = PATTERN_VERSION.search(version)
        if match:
            major = int(match.group(1))
            minor = int(match.group(2))
            patch = int(match.group(3))
            return dict(major=major, minor=minor, patch=patch)
    except:
        pass


def parse_jar(jar):
    try:
        tokens = jar.split("-")
        version = tokens[-2]
        version_parts = parse_version_parts(version)
        artifact = "-".join(tokens[:-2])
        return dict(
            jar=jar,
            artifact=artifact,
            version=version,
            version_parts=version_parts,
        )
    except:
        pass


def jar_sort_key(jar):
    vp = jar.get("version_parts")
    if not vp:
        vp = {}
    return jar.get("artifact"), vp.get("major"), vp.get("minor"), vp.get("patch")


def group_jars(records):
    """
    Groups artifacts by versioned jars
    """
    return dict(
        [
            (artifact, list(group))
            for artifact, group in groupby(
                sorted(
                    [
                        parse_jar(jar)
                        for jar in set(
                            [
                                record["jar"]
                                for record in records
                                if record["jar"] and record["jar"] != JDK
                            ]
                        )
                    ],
                    key=jar_sort_key,
                    reverse=True,
                ),
                key=lambda jar: jar["artifact"],
            )
        ]
    )


def find_matches(index, patterns, ignorecase=False, latest=False, exact_name=False):
    """
    Searches index for matching classes.
    """
    flags = 0
    if ignorecase:
        flags |= re.IGNORECASE
    records = sorted(
        [
            classname
            for classname in index["classnames"]
            if classname_matches(
                classname, patterns, flags=flags, exact_name=exact_name
            )
        ],
        key=lambda x: (x["name"], x["jar"]),
    )
    if latest:
        latest_jars = set([group[0]["jar"] for group in group_jars(records).values()])
        records = [
            record
            for record in records
            if record["jar"] is None
            or record["jar"] == JDK
            or record["jar"] in latest_jars
        ]
    return records


def check_modified_pomfiles(index):
    """
    Logs warnings if any build files have changed since last indexing.
    """
    for pathname, metadata in index["pomfiles"].items():
        if metadata["last_modified"] < get_last_modified_time(pathname):
            sys.stderr.write(f"! POM file has changed since last index: {pathname}\n")


def log_warning(lines):
    """
    Logs a more visible warning.
    """
    logging.warning(120 * "!")
    for line in lines:
        logging.warning("!! %s", line)
    logging.warning(120 * "!")


def download():
    """
    Downloads Javadoc for all local projects.

    Note: Gradle isn't supported currently, so those projects will need to
    manually download their sources and Javadocs.
    """
    for pathname in list_build_files():
        basename = os.path.basename(pathname)
        if basename == "pom.xml":
            command = [
                "mvn",
                "-f",
                pathname,
                "dependency:resolve",
                "-Dclassifier=javadoc",
            ]
            logging.info("Running %s", " ".join(command))
            subprocess.check_call(command)
        elif basename == "build.gradle":
            # TODO Support build.gradle
            #
            # IIUC one has to set the idea { module { downloadJavadoc = true } } setting,
            # and there's no standardized way to download all the javadoc like there is
            # for Maven. Gradle versions / gradlew might also factor in here.
            log_warning(
                [
                    "Gradle build file unsupported. Please configure gradle to download sources then download them manually.",
                    f"Build file: {pathname}",
                ]
            )
        else:
            logging.error("Unknown build file: %s", pathname)


def search(
    dirname, patterns, ignorecase=False, format_=None, latest=False, exact_name=False
):
    """
    Finds classes matching patterns.
    """
    seen = set()
    index = load_index(dirname)
    check_modified_pomfiles(index)
    for i, match in enumerate(
        find_matches(
            index,
            patterns,
            ignorecase=ignorecase,
            latest=latest,
            exact_name=exact_name,
        )
    ):
        match_key = "/".join([match["name"], match["jar"]])
        if match_key in seen:
            continue
        else:
            seen.add(match_key)
        match_cols = ["name", "jar", "javadoc", "source"]
        match_row = [
            match["name"],
            match["jar"],
            (
                match["path"]
                if match["jar"] == JDK
                else "file://"
                + os.path.join(dirname, DIRNAME_JAVADOC, match["jar"], match["path"])
            ),
            (
                None
                if match["jar"] == JDK
                else "file://"
                + os.path.join(
                    dirname,
                    DIRNAME_SOURCES,
                    match["jar"].replace("javadoc", "sources"),
                    match["path"].replace(".html", ".java"),
                )
            ),
        ]
        match_dict = dict(zip(match_cols, match_row))
        if not format_:
            if i > 0:
                print()
            print("   name: " + match_dict["name"])
            print("    jar: " + match_dict["jar"])
            print("javadoc: " + match_dict["javadoc"])
            if match_dict["source"]:
                print(" source: " + match_dict["source"])
        elif format_ == "tsv":
            sys.stdout.write("\t".join(match_row) + "\n")
        elif format_ == "csv":
            sys.stdout.write(",".join(match_row) + "\n")
        elif format_ == "json":
            sys.stdout.write(json.dumps(match_dict) + "\n")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Search for Javadoc by class nmae and JAR"
    )
    parser.add_argument(
        "--download",
        action="store_true",
        help="Scan for Java projects and download dependency Javadoc",
    )
    parser.add_argument(
        "--index",
        action="store_true",
        help="Extract Javadoc from JARs and build class name index",
    )
    parser.add_argument(
        "-m",
        "--maven_repo",
        default=DEFAULT_MAVEN,
        help="Location of local Maven repository",
    )
    parser.add_argument(
        "-g",
        "--gradle_repo",
        default=DEFAULT_GRADLE,
        help="Location of local Gradle repository",
    )
    parser.add_argument(
        "-o",
        "--output",
        default=DEFAULT_OUTPUT,
        help="Location of extracted Javadoc and index",
    )
    parser.add_argument(
        "-i", "--ignorecase", action="store_true", help="Case-insensitive matching"
    )
    parser.add_argument(
        "-f",
        "--format",
        choices=["tsv", "csv", "json"],
        help="Format of output results",
    )
    parser.add_argument("--debug", action="store_true", help="Verbose debug logging")
    parser.add_argument(
        "--delete", action="store_true", help="Delete any existing jdoc index"
    )
    parser.add_argument(
        "-l",
        "--latest",
        action="store_true",
        help="Only include latest version of JARs",
    )
    parser.add_argument(
        "-e",
        "--exact_name",
        action="store_true",
        help="Match the class name exactly (excluding package)",
    )
    parser.add_argument(
        "patterns",
        nargs="*",
        help="Match class and JAR names against these regular expressions",
    )
    args = parser.parse_args()
    logging.basicConfig(
        format="%(message)s",
        level=logging.DEBUG if args.debug else logging.INFO,
        stream=sys.stdout,
    )
    if args.download or args.index:
        if args.download:
            download()
        if args.index:
            index(
                args.maven_repo,
                args.gradle_repo,
                args.output,
                delete=args.delete,
            )
    else:
        search(
            args.output,
            args.patterns,
            ignorecase=args.ignorecase,
            format_=args.format,
            latest=args.latest,
            exact_name=args.exact_name,
        )
