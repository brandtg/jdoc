#!/usr/bin/env python3
import logging
import argparse
import os
import re
import sys
import json
import zipfile
import subprocess
import shutil
from html.parser import HTMLParser

DEFAULT_MAVEN = os.path.join(os.environ["HOME"], ".m2")
DEFAULT_GRADLE = os.path.join(os.environ["HOME"], ".gradle")
DEFAULT_OUTPUT = os.path.join(os.environ["HOME"], "jdoc")
FILENAME_INDEX = "_index.json"
FILENAME_CLASS = ["allclasses-noframe.html", "allclasses-index.html"]


def index_javadoc(repodir, outputdir):
    if not os.path.exists(repodir):
        logging.warning("Repo does not exist: %s", repodir)
        return
    logging.info("Indexing repo: %s", repodir)
    os.makedirs(outputdir, exist_ok=True)
    for root, dirnames, filenames in os.walk(repodir):
        for filename in filenames:
            if filename.endswith("-javadoc.jar"):
                pathname_input = os.path.join(root, filename)
                pathname_output = os.path.join(outputdir, filename)
                if not os.path.exists(pathname_output):
                    logging.debug(
                        "Extracting %s to %s", pathname_input, pathname_output
                    )
                    os.makedirs(pathname_output, exist_ok=True)
                    with zipfile.ZipFile(pathname_input) as zf:
                        zf.extractall(pathname_output)


class LinkExtractor(HTMLParser):
    def __init__(self):
        super().__init__()
        self.links = []

    def _is_code(self, title):
        return title and ("class in" in title or "interface in" in title)

    def _is_local(self, href):
        return href and "http://" not in href and "https://" not in href

    def handle_starttag(self, tag, attrs):
        if tag == "a":
            attrs = dict(attrs)
            title = attrs.get("title")
            href = attrs.get("href")
            if self._is_code(title) and self._is_local(href):
                self.links.append(href)

    def get_links(self):
        return self.links


def parse_classnames(root, html_content):
    parser = LinkExtractor()
    parser.feed(html_content)
    return [
        dict(
            name=link.replace(".html", "").replace("/", "."),
            path=link,
            jar=os.path.basename(root),
        )
        for link in parser.get_links()
    ]


def list_build_files():
    for root, dirnames, filenames in os.walk(os.environ["HOME"]):
        dirnames[:] = [
            d for d in dirnames if d not in ["jdoc", "tmp"] and not d.startswith(".")
        ]
        for filename in filenames:
            if filename == "pom.xml" or filename == "build.gradle":
                pathname = os.path.join(root, filename)
                yield pathname


def get_last_modified_time(pathname):
    return int(os.path.getmtime(pathname))


def index_json(outputdir):
    logging.info("Building %s", FILENAME_INDEX)
    # Find classnames and their associated Javadoc files
    classnames = []
    for root, dirnames, filenames in os.walk(outputdir):
        for filename in filenames:
            if filename in FILENAME_CLASS:
                pathname = os.path.join(root, filename)
                logging.debug("Processing %s", pathname)
                with open(pathname) as f:
                    html_content = f.read()
                    classnames.extend(parse_classnames(root, html_content))
    # Find build files and record their last modified times
    pomfiles = {}
    for pathname in list_build_files():
        last_modified = get_last_modified_time(pathname)
        logging.info("Build file %s last modified at %s", pathname, last_modified)
        pomfiles[pathname] = dict(last_modified=last_modified)
    # Write JSON file
    with open(os.path.join(outputdir, FILENAME_INDEX), "w") as f:
        json.dump(dict(classnames=classnames, pomfiles=pomfiles), f)


def index(mavendir, gradledir, outputdir, delete=False):
    if delete and os.path.exists(outputdir):
        logging.info("Deleting %s", outputdir)
        shutil.rmtree(outputdir)
    index_javadoc(mavendir, outputdir)
    index_javadoc(gradledir, outputdir)
    index_json(outputdir)


def load_index(dirname):
    with open(os.path.join(dirname, FILENAME_INDEX)) as f:
        return json.load(f)


def classname_matches(classname, patterns, flags=0):
    if patterns:
        for pattern in patterns:
            if not re.search(pattern, classname["name"], flags) and not re.search(
                pattern, classname["jar"], flags
            ):
                return False
    return True


def find_matches(index, patterns, ignorecase=False):
    flags = 0
    if ignorecase:
        flags |= re.IGNORECASE
    return sorted(
        [
            classname
            for classname in index["classnames"]
            if classname_matches(classname, patterns, flags=flags)
        ],
        key=lambda x: (x["name"], x["jar"]),
    )


def check_modified_pomfiles(index):
    for pathname, metadata in index["pomfiles"].items():
        if metadata["last_modified"] < get_last_modified_time(pathname):
            sys.stderr.write(f"! POM file has changed since last index: {pathname}\n")


def log_warning(lines):
    logging.warning(120 * "!")
    for line in lines:
        logging.warning("!! %s", line)
    logging.warning(120 * "!")


def download():
    for pathname in list_build_files():
        basename = os.path.basename(pathname)
        if basename == "pom.xml":
            command = [
                "mvn",
                "-f",
                pathname,
                "dependency:resolve",
                "-Dclassifier=javadoc",
            ]
            logging.info("Running %s", " ".join(command))
            subprocess.check_call(command)
        elif basename == "build.gradle":
            # TODO Support build.gradle
            #
            # IIUC one has to set the idea { module { downloadJavadoc = true } } setting,
            # and there's no standardized way to download all the javadoc like there is
            # for Maven. Gradle versions / gradlew might also factor in here.
            log_warning(
                [
                    "Gradle build file unsupported. Please configure gradle to download sources then download them manually.",
                    f"Build file: {pathname}",
                ]
            )
        else:
            logging.error("Unknown build file: %s", pathname)


def search(dirname, patterns, ignorecase=False, format_=None):
    index = load_index(dirname)
    check_modified_pomfiles(index)
    for match in find_matches(index, patterns, ignorecase=ignorecase):
        match_pathname = os.path.join(dirname, match["jar"], match["path"])
        match_row = [match["name"], match["jar"], f"file://{match_pathname}"]
        if not format_ or format_ == "tsv":
            sys.stdout.write("\t".join(match_row) + "\n")
        elif format_ == "csv":
            sys.stdout.write(",".join(match_row) + "\n")
        elif format_ == "json":
            sys.stdout.write(
                json.dumps(dict(zip(["name", "jar", "path"], match_row))) + "\n"
            )


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--index", action="store_true")
    parser.add_argument("--download", action="store_true")
    parser.add_argument("-m", "--maven_repo", default=DEFAULT_MAVEN)
    parser.add_argument("-g", "--gradle_repo", default=DEFAULT_GRADLE)
    parser.add_argument("-o", "--output", default=DEFAULT_OUTPUT)
    parser.add_argument("-i", "--ignorecase", action="store_true")
    parser.add_argument("-f", "--format", choices=["tsv", "csv", "json"])
    parser.add_argument("--debug", action="store_true")
    parser.add_argument("--delete", action="store_true")
    parser.add_argument("patterns", nargs="*")
    args = parser.parse_args()
    logging.basicConfig(
        format="%(message)s",
        level=logging.DEBUG if args.debug else logging.INFO,
        stream=sys.stdout,
    )
    if args.download:
        download()
    elif args.index:
        index(
            args.maven_repo,
            args.gradle_repo,
            args.output,
            delete=args.delete,
        )
    else:
        search(
            args.output,
            args.patterns,
            ignorecase=args.ignorecase,
            format_=args.format,
        )
