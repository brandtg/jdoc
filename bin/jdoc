#!/usr/bin/env python3
import logging
import argparse
import os
import re
import sys
import json
import zipfile
import subprocess
import shutil
import textwrap
from itertools import groupby
from html.parser import HTMLParser
from urllib import request

DEFAULT_MAVEN = os.path.join(os.environ["HOME"], ".m2")
DEFAULT_GRADLE = os.path.join(os.environ["HOME"], ".gradle")
DEFAULT_OUTPUT = os.path.join(os.environ["HOME"], "jdoc")
FILENAME_INDEX = "_index.json"
FILENAME_CLASS = [
    "allclasses-noframe.html",
    "allclasses-index.html",
    "overview-tree.html",
]
JDK = "JDK"


def index_javadoc(repodir, outputdir):
    """
    Extracts Javadoc archives.

    :param repodir: Root directory of local Maven or Gradle repo.
    :param outputdir: Extract Javadoc into this directory.
    """
    if not os.path.exists(repodir):
        logging.warning("Repo does not exist: %s", repodir)
        return
    logging.info("Indexing repo: %s", repodir)
    os.makedirs(outputdir, exist_ok=True)
    for root, dirnames, filenames in os.walk(repodir):
        for filename in filenames:
            if filename.endswith("-javadoc.jar"):
                pathname_input = os.path.join(root, filename)
                pathname_output = os.path.join(outputdir, filename)
                if not os.path.exists(pathname_output):
                    logging.debug(
                        "Extracting %s to %s", pathname_input, pathname_output
                    )
                    os.makedirs(pathname_output, exist_ok=True)
                    with zipfile.ZipFile(pathname_input) as zf:
                        zf.extractall(pathname_output)


class LinkExtractor(HTMLParser):
    """
    Extracts links to local Javadoc from an HTML document.
    """

    def __init__(self, include_external=False):
        """
        :param include_external: If False, only consider local links.
            This should be set to true if processing Javadoc that lives
            on the web, e.g. the core JDK docs.
        """
        super().__init__()
        self.include_external = include_external
        self.links = []

    def _is_code(self, title):
        """
        :param title: The link title text in a Javadoc index page.
        :return: True if the link is to a class or interface.
        """
        return title and ("class in" in title or "interface in" in title)

    def _is_local(self, href):
        """
        :param href: The link URL.
        :return: True if the link is to an HTML file that exists locally.
        """
        return (
            href
            and "http://" not in href
            and "https://" not in href
            and "is-external=true" not in href
        )

    def handle_starttag(self, tag, attrs):
        if tag == "a":
            attrs = dict(attrs)
            title = attrs.get("title")
            href = attrs.get("href")
            if self._is_code(title) and (self.include_external or self._is_local(href)):
                self.links.append(href)

    def get_links(self):
        """
        :return: List of the extracted links to classes and interfaces.
        """
        return self.links


def parse_classnames(root, html_content):
    """
    Extracts all classes and interfaces from Javadoc index.

    :param root: The directory containing the Javadoc.
    :param html_content: The content of the Javadoc page.
    :return: A list of records with the fully-qualified class name,
        the path to the Javadoc file in the index (for viewing), and
        the jar file it came from, which contains version information.
    """
    parser = LinkExtractor()
    parser.feed(html_content)
    return [
        dict(
            name=link.replace(".html", "").replace("/", "."),
            path=link,
            jar=os.path.basename(root),
        )
        for link in parser.get_links()
    ]


def list_build_files():
    """
    Finds all Maven/Gradle build files in user's home directory.

    :yield: The absolute path to the build file.
    """
    for root, dirnames, filenames in os.walk(os.environ["HOME"]):
        dirnames[:] = [
            d for d in dirnames if d not in ["jdoc", "tmp"] and not d.startswith(".")
        ]
        for filename in filenames:
            if filename == "pom.xml" or filename == "build.gradle":
                pathname = os.path.join(root, filename)
                yield pathname


def get_last_modified_time(pathname):
    """
    :return: The last modified time of ``pathname``.
    """
    return int(os.path.getmtime(pathname))


def get_java_version():
    """
    Runs ``java -version`` and extracts the major version.

    :return: The major version of Java found on the user's path.
    """
    output = subprocess.check_output(
        ["java", "-version"], stderr=subprocess.STDOUT
    ).decode("utf-8")
    match = re.search(r'version "(\d+)\.', output)
    if not match:
        raise Exception("Could not find Java version in output of java -version")
    java_version = int(match.group(1))
    logging.info("Identified system Java version as %s", java_version)
    return java_version


def parse_standard_library_classnames(java_version):
    """
    Finds links to Javadoc for the JDK from the web.

    :param java_version: The major version of Java
    :return: A list of records with the fully-qualified class name,
        the path to the Javadoc file in the index (for viewing), and
        the jar file it came from, which contains version information.
    """
    base_url = (
        "https://docs.oracle.com/en/java/javase/" + str(java_version) + "/docs/api/"
    )
    all_classes_url = base_url + "allclasses-index.html"
    with request.urlopen(all_classes_url) as response:
        logging.info("GET %s => %s", all_classes_url, response.getcode())
        html_content = response.read().decode("utf-8")
        parser = LinkExtractor(include_external=True)
        parser.feed(html_content)
        return [
            dict(
                name=link.replace(".html", "").replace("/", "."),
                path=base_url + link,
                jar=JDK,
            )
            for link in parser.get_links()
        ]


def index_json(outputdir):
    """
    Builds the JSON index file containing all classes.

    The index file consists of a list of all the classes and the location
    of their Javadocs, and a mapping of all local build files to their last
    changed timestamp, so we can know if dependencies have changed.

    :param outputdir: Write JSON index file into this directory.
    """
    logging.info("Building %s", FILENAME_INDEX)
    # Find classnames from standard library and libraries
    classnames = []
    classnames.extend(parse_standard_library_classnames(get_java_version()))
    for root, dirnames, filenames in os.walk(outputdir):
        for filename in filenames:
            if filename in FILENAME_CLASS:
                pathname = os.path.join(root, filename)
                logging.debug("Processing %s", pathname)
                with open(pathname, encoding="unicode_escape") as f:
                    html_content = f.read()
                    classnames.extend(parse_classnames(root, html_content))
    # Find build files and record their last modified times
    pomfiles = {}
    for pathname in list_build_files():
        last_modified = get_last_modified_time(pathname)
        logging.info("Build file %s last modified at %s", pathname, last_modified)
        pomfiles[pathname] = dict(last_modified=last_modified)
    # Write JSON file
    with open(os.path.join(outputdir, FILENAME_INDEX), "w") as f:
        json.dump(dict(classnames=classnames, pomfiles=pomfiles), f)


def index(mavendir, gradledir, outputdir, delete=False):
    """
    Runs indexing pipeline.

    :param mavendir: Location of Maven repository.
    :param gradledir: Location of Gradle repository.
    :param outputdir: Directory for extracted javadoc and index JSON file.
    :param delete: If True, delete any existing outputdir before indexing.
    """
    if delete and os.path.exists(outputdir):
        logging.info("Deleting %s", outputdir)
        shutil.rmtree(outputdir)
    index_javadoc(mavendir, outputdir)
    index_javadoc(gradledir, outputdir)
    index_json(outputdir)


def load_index(dirname):
    """
    :return: The index JSON file.
    """
    with open(os.path.join(dirname, FILENAME_INDEX)) as f:
        return json.load(f)


def classname_matches(classname, patterns, flags=0):
    """
    Returns True if a class matches search patterns.

    :param classname: The class record.
    :param patterns: A list of regular expressions.
    :param flags: Passed to ``re.search``.
    :return: True if the class name or jar matches one of the patterns.
    """
    if patterns:
        for pattern in patterns:
            if not re.search(pattern, classname["name"], flags) and not re.search(
                pattern, classname["jar"], flags
            ):
                return False
    return True


PATTERN_VERSION = re.compile(r"(\d+)\.(\d+)\.(\d+)")


def parse_version_parts(version):
    try:
        match = PATTERN_VERSION.search(version)
        if match:
            major = int(match.group(1))
            minor = int(match.group(2))
            patch = int(match.group(3))
            return dict(major=major, minor=minor, patch=patch)
    except:
        pass


def parse_jar(jar):
    try:
        tokens = jar.split("-")
        version = tokens[-2]
        version_parts = parse_version_parts(version)
        artifact = "-".join(tokens[:-2])
        return dict(
            jar=jar,
            artifact=artifact,
            version=version,
            version_parts=version_parts,
        )
    except:
        pass


def jar_sort_key(jar):
    vp = jar.get("version_parts")
    if not vp:
        vp = {}
    return jar.get("artifact"), vp.get("major"), vp.get("minor"), vp.get("patch")


def group_jars(records):
    """
    :param records: A list of classes.
    :return: The jars grouped by artifact, sorted by version.
    """
    return dict(
        [
            (artifact, list(group))
            for artifact, group in groupby(
                sorted(
                    [
                        parse_jar(jar)
                        for jar in set(
                            [
                                record["jar"]
                                for record in records
                                if record["jar"] and record["jar"] != JDK
                            ]
                        )
                    ],
                    key=jar_sort_key,
                    reverse=True,
                ),
                key=lambda jar: jar["artifact"],
            )
        ]
    )


def find_matches(index, patterns, ignorecase=False, latest=False):
    """
    Searches index for matching classes.

    :param index: Structure with records for all classes.
    :param patterns: A list of regular expressions.
    :param ignorecase: If True perform case-insensitive matching.
    :return: A sorted list of all classes matching a search query.
    """
    flags = 0
    if ignorecase:
        flags |= re.IGNORECASE
    records = sorted(
        [
            classname
            for classname in index["classnames"]
            if classname_matches(classname, patterns, flags=flags)
        ],
        key=lambda x: (x["name"], x["jar"]),
    )
    if latest:
        latest_jars = set([group[0]["jar"] for group in group_jars(records).values()])
        records = [
            record
            for record in records
            if record["jar"] is None
            or record["jar"] == JDK
            or record["jar"] in latest_jars
        ]
    return records


def check_modified_pomfiles(index):
    """
    Logs warnings if any build files have changed since last indexing.

    :param index: Structure with last modified times of all build files.
    """
    for pathname, metadata in index["pomfiles"].items():
        if metadata["last_modified"] < get_last_modified_time(pathname):
            sys.stderr.write(f"! POM file has changed since last index: {pathname}\n")


def log_warning(lines):
    """
    Logs a more visible warning.

    :param lines: A list of strings.
    """
    logging.warning(120 * "!")
    for line in lines:
        logging.warning("!! %s", line)
    logging.warning(120 * "!")


def download():
    """
    Downloads Javadoc for all local projects.

    Note: Gradle isn't supported currently, so those projects will need to
    manually download their sources and Javadocs.
    """
    for pathname in list_build_files():
        basename = os.path.basename(pathname)
        if basename == "pom.xml":
            command = [
                "mvn",
                "-f",
                pathname,
                "dependency:resolve",
                "-Dclassifier=javadoc",
            ]
            logging.info("Running %s", " ".join(command))
            subprocess.check_call(command)
        elif basename == "build.gradle":
            # TODO Support build.gradle
            #
            # IIUC one has to set the idea { module { downloadJavadoc = true } } setting,
            # and there's no standardized way to download all the javadoc like there is
            # for Maven. Gradle versions / gradlew might also factor in here.
            log_warning(
                [
                    "Gradle build file unsupported. Please configure gradle to download sources then download them manually.",
                    f"Build file: {pathname}",
                ]
            )
        else:
            logging.error("Unknown build file: %s", pathname)


class JavadocExtractor(HTMLParser):
    # TODO inheritance
    # TODO description
    # TODO summary
    def __init__(self):
        super().__init__()
        self.target = None
        self.recording = None
        self.record = {}

    def handle_starttag(self, tag, attrs):
        attrs = dict(attrs)
        clazz = attrs.get("class", "")
        if "title" in clazz:
            self.target = tag
            self.recording = "title"
        elif "subTitle" in clazz:
            self.target = tag
            self.recording = "subtitle"
        elif "description" in clazz:
            self.target = tag
            self.recording = "description"
            self.record["description"] = []

    def handle_data(self, data):
        if self.recording:
            if self.recording in ["description"]:
                self.record[self.recording].append(data)
            else:
                self.record[self.recording] = data

    def handle_endtag(self, tag):
        if self.target == tag:
            self.recording = None

    def get_description_section(self, section):
        return "\n".join(textwrap.wrap(re.sub(r"\s+", " ", section).strip(), width=80))

    def get_description(self):
        sections = ("".join(self.record["description"]).strip()).split("\n\n")
        description = "\n\n".join(
            [
                sections[0],
                *[self.get_description_section(section) for section in sections[1:]],
            ]
        )
        return description

    def format(self):
        description = self.get_description()
        return "\n\n".join([description])


def format_javadoc(dirname, record):
    with open(os.path.join(dirname, record["jar"], record["path"])) as f:
        html_content = f.read()
        parser = JavadocExtractor()
        parser.feed(html_content)
        return parser.format()


def search(
    dirname,
    patterns,
    ignorecase=False,
    format_=None,
    latest=False,
    short=False,
    view=False,
):
    """
    Finds classes matching patterns.

    :param dirname: Path to the index and extracted Javadocs.
    :param patterns: Match classes against these regular expressions.
    :param ignorecase: Perform case-insensitive matching.
    :param format_: Output format, either csv, tsv, or json.
    :param latest: Only show the latest JAR version.
    :param short: Only show the class name.
    :param view: View the class documentation on the command line.
    """
    seen = set()
    index = load_index(dirname)
    check_modified_pomfiles(index)
    for idx, match in enumerate(
        find_matches(index, patterns, ignorecase=ignorecase, latest=latest)
    ):
        match_key = "/".join([match["name"], match["jar"]])
        if match_key in seen:
            continue
        else:
            seen.add(match_key)
        if view:
            if idx > 0:
                sys.stdout.write((80 * "-") + "\n")
            sys.stdout.write(format_javadoc(dirname, match) + "\n")
        else:
            match_row = (
                [match["name"]]
                if short
                else [
                    match["name"],
                    match["jar"],
                    (
                        match["path"]
                        if match["jar"] == "JDK"
                        else "file://"
                        + os.path.join(dirname, match["jar"], match["path"])
                    ),
                ]
            )
            if not format_ or format_ == "tsv":
                sys.stdout.write("\t".join(match_row) + "\n")
            elif format_ == "csv":
                sys.stdout.write(",".join(match_row) + "\n")
            elif format_ == "json":
                sys.stdout.write(
                    json.dumps(dict(zip(["name", "jar", "path"], match_row))) + "\n"
                )


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Search for Javadoc by class nmae and JAR"
    )
    parser.add_argument(
        "--download",
        action="store_true",
        help="Scan for Java projects and download dependency Javadoc",
    )
    parser.add_argument(
        "--index",
        action="store_true",
        help="Extract Javadoc from JARs and build class name index",
    )
    parser.add_argument(
        "-m",
        "--maven_repo",
        default=DEFAULT_MAVEN,
        help="Location of local Maven repository",
    )
    parser.add_argument(
        "-g",
        "--gradle_repo",
        default=DEFAULT_GRADLE,
        help="Location of local Gradle repository",
    )
    parser.add_argument(
        "-o",
        "--output",
        default=DEFAULT_OUTPUT,
        help="Location of extracted Javadoc and index",
    )
    parser.add_argument(
        "-i", "--ignorecase", action="store_true", help="Case-insensitive matching"
    )
    parser.add_argument(
        "-s", "--short", action="store_true", help="Shorten output to just class name"
    )
    parser.add_argument(
        "-f",
        "--format",
        choices=["tsv", "csv", "json"],
        help="Format of output results",
    )
    parser.add_argument("--debug", action="store_true", help="Verbose debug logging")
    parser.add_argument(
        "--delete", action="store_true", help="Delete any existing jdoc index"
    )
    parser.add_argument(
        "--latest", action="store_true", help="Only include latest version of JARs"
    )
    parser.add_argument(
        "--view",
        action="store_true",
        help="View the documentation for the matching class on the command line",
    )
    parser.add_argument(
        "patterns",
        nargs="*",
        help="Match class and JAR names against these regular expressions",
    )
    args = parser.parse_args()
    logging.basicConfig(
        format="%(message)s",
        level=logging.DEBUG if args.debug else logging.INFO,
        stream=sys.stdout,
    )
    if args.download or args.index:
        if args.download:
            download()
        if args.index:
            index(
                args.maven_repo,
                args.gradle_repo,
                args.output,
                delete=args.delete,
            )
    else:
        search(
            args.output,
            args.patterns,
            ignorecase=args.ignorecase,
            format_=args.format,
            latest=args.latest,
            short=args.short,
            view=args.view,
        )
