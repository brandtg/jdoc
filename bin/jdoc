#!/usr/bin/env python3
import logging
import argparse
import os
import re
import sys
import json
import zipfile
import subprocess
from bs4 import BeautifulSoup

DEFAULT_MAVEN = os.path.join(os.environ["HOME"], ".m2")
DEFAULT_OUTPUT = os.path.join(os.environ["HOME"], "jdoc")
FILENAME_INDEX = "_index.json"


def index_maven(repodir, outputdir):
    if not os.path.exists(repodir):
        logging.warning("Maven repo does not exist: %s", repodir)
        return
    logging.info("Indexing Maven repo: %s", repodir)
    os.makedirs(outputdir, exist_ok=True)
    for root, dirnames, filenames in os.walk(repodir):
        for filename in filenames:
            if filename.endswith("-javadoc.jar"):
                pathname_input = os.path.join(root, filename)
                pathname_output = os.path.join(outputdir, filename)
                if not os.path.exists(pathname_output):
                    logging.debug(
                        "Extracting %s to %s", pathname_input, pathname_output
                    )
                    os.makedirs(pathname_output, exist_ok=True)
                    with zipfile.ZipFile(pathname_input) as zf:
                        zf.extractall(pathname_output)


def parse_classnames(root, tree):
    return [
        dict(
            name=elt["href"].replace(".html", "").replace("/", "."),
            path=elt["href"],
            jar=os.path.basename(root),
        )
        for elt in tree.select("a")
        if elt.get("title") and "class in" in elt.get("title")
    ]


def list_pom_files():
    for root, dirnames, filenames in os.walk(os.environ["HOME"]):
        dirnames[:] = [
            d for d in dirnames if d not in ["jdoc", "tmp"] and not d.startswith(".")
        ]
        for filename in filenames:
            if filename == "pom.xml":
                pathname = os.path.join(root, filename)
                yield pathname


def get_last_modified_time(pathname):
    return int(os.path.getmtime(pathname))


def index_json(outputdir):
    # Find classnames and their associated Javadoc files
    classnames = []
    for root, dirnames, filenames in os.walk(outputdir):
        for filename in filenames:
            if filename == "allclasses-noframe.html":
                pathname = os.path.join(root, filename)
                logging.debug("Processing %s", pathname)
                with open(pathname) as f:
                    tree = BeautifulSoup(f, "html.parser")
                    classnames.extend(parse_classnames(root, tree))
    # Find pom.xml files and record their last modified times
    pomfiles = {}
    for pathname in list_pom_files():
        pomfiles[pathname] = dict(last_modified=get_last_modified_time(pathname))
    # Write JSON file
    with open(os.path.join(outputdir, FILENAME_INDEX), "w") as f:
        json.dump(dict(classnames=classnames, pomfiles=pomfiles), f)


def index(mavendir, outputdir):
    index_maven(mavendir, outputdir)
    index_json(outputdir)


def load_index(dirname):
    with open(os.path.join(dirname, FILENAME_INDEX)) as f:
        return json.load(f)


def classname_matches(classname, patterns, flags=0):
    if patterns:
        for pattern in patterns:
            if not re.search(pattern, classname["name"], flags) and not re.search(
                pattern, classname["jar"], flags
            ):
                return False
    return True


def find_matches(index, patterns, ignorecase=False):
    flags = 0
    if ignorecase:
        flags |= re.IGNORECASE
    return sorted(
        [
            classname
            for classname in index["classnames"]
            if classname_matches(classname, patterns, flags=flags)
        ],
        key=lambda x: (x["name"], x["jar"]),
    )


def check_modified_pomfiles(index):
    for pathname, metadata in index["pomfiles"].items():
        if metadata["last_modified"] < get_last_modified_time(pathname):
            sys.stderr.write(f"! POM file has changed since last index: {pathname}\n")


def search(dirname, patterns, ignorecase=False):
    index = load_index(dirname)
    check_modified_pomfiles(index)
    for match in find_matches(index, patterns, ignorecase=ignorecase):
        pathname = os.path.join(dirname, match["jar"], match["path"])
        logging.info("%s (file://%s)", match["name"], pathname)


def download():
    for pathname in list_pom_files():
        command = [
            "mvn",
            "-f",
            pathname,
            "dependency:resolve",
            "-Dclassifier=javadoc",
        ]
        logging.info("Running %s", " ".join(command))
        subprocess.check_call(command)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--index", action="store_true")
    parser.add_argument("--download", action="store_true")
    parser.add_argument("-m", "--maven_repo", default=DEFAULT_MAVEN)
    parser.add_argument("-o", "--output", default=DEFAULT_OUTPUT)
    parser.add_argument("-i", "--ignorecase", action="store_true")
    parser.add_argument("--debug", action="store_true")
    parser.add_argument("patterns", nargs="*")
    args = parser.parse_args()
    logging.basicConfig(
        format="%(message)s",
        level=logging.DEBUG if args.debug else logging.INFO,
        stream=sys.stdout,
    )
    # TODO Check to see if pom.xml have changed since the last time they were downloaded / indexed
    if args.download:
        download()
    elif args.index:
        index(args.maven_repo, args.output)
    else:
        search(args.output, args.patterns, ignorecase=args.ignorecase)
